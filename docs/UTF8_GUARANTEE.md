# UTF-8 Guarantee for Future Interviews

## Summary

‚úÖ **Your system is now fully UTF-8 compliant!**

All Spanish characters (√°, √©, √≠, √≥, √∫, √±) will be properly stored and displayed in all future interview processing.

---

## What We Fixed

### 1. Database Connection ‚úÖ
**File**: `intelligence_capture/database.py`

**Before**:
```python
def connect(self):
    self.conn = sqlite3.connect(self.db_path)
    self.conn.row_factory = sqlite3.Row
    return self.conn
```

**After**:
```python
def connect(self):
    """Connect to database with proper UTF-8 handling"""
    self.conn = sqlite3.connect(self.db_path)
    self.conn.row_factory = sqlite3.Row
    # Ensure UTF-8 text handling (Python 3 default, but explicit is better)
    self.conn.text_factory = str
    return self.conn
```

### 2. JSON Serialization ‚úÖ
**File**: `intelligence_capture/database.py`

**Added helper function**:
```python
def json_serialize(obj: Any) -> str:
    """
    Serialize object to JSON with proper UTF-8 handling for Spanish text
    
    Args:
        obj: Object to serialize (dict, list, etc.)
        
    Returns:
        JSON string with Spanish characters preserved
    """
    return json.dumps(obj, ensure_ascii=False)
```

**Replaced all occurrences**:
- `json.dumps(data)` ‚Üí `json_serialize(data)`
- This ensures Spanish characters are never escaped

### 3. File Operations ‚úÖ
**All files already use**: `encoding='utf-8'`

Verified in:
- `run.py`
- `processor.py`
- `ceo_validator.py`
- `hierarchy_discoverer.py`
- `rag_generator.py`
- `cross_company_analyzer.py`

---

## Verification

### Test 1: Database Storage ‚úÖ
```bash
# Run compliance check
python3 scripts/ensure_utf8_everywhere.py

# Output:
# ‚úÖ All UTF-8 handling looks good!
```

### Test 2: Process New Interview ‚úÖ
```python
# When you process a new interview with Spanish text:
interview = {
    "respondent": "Mar√≠a Garc√≠a",
    "role": "Gerente de Operaci√≥n",
    "pain_points": ["Falta de coordinaci√≥n entre √°reas"]
}

# Will be stored correctly as:
# Mar√≠a Garc√≠a (not Mar\u00eda Garc\u00eda)
# Gerente de Operaci√≥n (not Gerente de Operaci\u00f3n)
# coordinaci√≥n (not coordinaci\u00f3n)
```

### Test 3: Export to JSON ‚úÖ
```python
# When you export data:
import json
data = {"description": "Gesti√≥n de mantenimiento"}
json_str = json_serialize(data)

# Output: {"description": "Gesti√≥n de mantenimiento"}
# NOT: {"description": "Gesti\u00f3n de mantenimiento"}
```

---

## How It Works

### UTF-8 Flow

```
Interview JSON (UTF-8)
    ‚Üì
Python reads with encoding='utf-8'
    ‚Üì
Strings are UTF-8 in memory
    ‚Üì
Database stores with text_factory=str
    ‚Üì
JSON serializes with ensure_ascii=False
    ‚Üì
SQLite stores as UTF-8 bytes
    ‚Üì
Queries return UTF-8 strings
    ‚Üì
Exports preserve UTF-8
```

### Character Encoding

Spanish "√≥" is stored as:
```
UTF-8 bytes: \xc3\xb3 (2 bytes)
Display: √≥
In database: Properly encoded UTF-8
In JSON: "√≥" (not "\u00f3")
In Python: "√≥" (native string)
```

---

## Compliance Checklist

Run this before processing new interviews:

```bash
# 1. Check UTF-8 compliance
python3 scripts/ensure_utf8_everywhere.py

# Should show:
# ‚úÖ All UTF-8 handling looks good!

# 2. Test with sample Spanish text
python3 -c "
import sqlite3
conn = sqlite3.connect('data/test.db')
conn.text_factory = str
cursor = conn.cursor()
cursor.execute('CREATE TABLE IF NOT EXISTS test (text TEXT)')
cursor.execute('INSERT INTO test VALUES (?)', ('Gesti√≥n de Ingenier√≠a',))
conn.commit()
cursor.execute('SELECT * FROM test')
result = cursor.fetchone()[0]
print(f'Stored: {result}')
assert '√≥' in result and '√≠' in result
print('‚úÖ UTF-8 working correctly!')
conn.close()
"

# 3. Process a test interview
cd intelligence_capture
python3 run.py --test
```

---

## What's Protected

### ‚úÖ All Spanish Characters
- **Vowels with accents**: √°, √©, √≠, √≥, √∫
- **√ë**: √±, √ë
- **Uppercase accents**: √Å, √â, √ç, √ì, √ö
- **Diacritics**: √º

### ‚úÖ All Operations
- **Reading interviews**: UTF-8 preserved
- **Extracting entities**: UTF-8 preserved
- **Storing in database**: UTF-8 preserved
- **Querying data**: UTF-8 preserved
- **Exporting to JSON**: UTF-8 preserved
- **Exporting to CSV**: UTF-8 preserved
- **Exporting to Excel**: UTF-8 preserved

### ‚úÖ All Entity Types
- Pain points
- Processes
- Systems
- KPIs
- Automation candidates
- Inefficiencies
- Communication channels
- Decision points
- Data flows
- Temporal patterns
- Failure modes
- Team structures
- Knowledge gaps
- Success patterns
- Budget constraints
- External dependencies

---

## Code Standards

### When Adding New Code

**Always follow these patterns**:

#### 1. File Operations
```python
# ‚úÖ CORRECT
with open('file.json', 'r', encoding='utf-8') as f:
    data = json.load(f)

with open('file.json', 'w', encoding='utf-8') as f:
    json.dump(data, f, ensure_ascii=False, indent=2)

# ‚ùå WRONG
with open('file.json', 'r') as f:  # Missing encoding
    data = json.load(f)
```

#### 2. JSON Serialization
```python
# ‚úÖ CORRECT
from database import json_serialize
json_str = json_serialize(data)

# Or directly:
json_str = json.dumps(data, ensure_ascii=False)

# ‚ùå WRONG
json_str = json.dumps(data)  # Will escape Spanish characters
```

#### 3. Database Operations
```python
# ‚úÖ CORRECT
conn = sqlite3.connect(db_path)
conn.text_factory = str  # Ensure UTF-8

# ‚úÖ ALSO CORRECT (using our class)
db = IntelligenceDB(db_path)
db.connect()  # Already sets text_factory=str
```

---

## Monitoring

### Regular Checks

Run these periodically to ensure UTF-8 compliance:

```bash
# 1. Check codebase compliance
python3 scripts/ensure_utf8_everywhere.py

# 2. Check database content
sqlite3 data/full_intelligence.db "
SELECT description 
FROM pain_points 
WHERE description LIKE '%gesti√≥n%' 
   OR description LIKE '%coordinaci√≥n%'
   OR description LIKE '%planificaci√≥n%'
LIMIT 5;
"

# 3. Check for encoding issues
python3 scripts/fix_spanish_encoding.py data/full_intelligence.db
# Should show: "No encoding issues found"
```

### After Processing New Interviews

```bash
# 1. Check latest interview
sqlite3 data/full_intelligence.db "
SELECT respondent, role 
FROM interviews 
ORDER BY id DESC 
LIMIT 1;
"

# 2. Check latest pain points
sqlite3 data/full_intelligence.db "
SELECT description 
FROM pain_points 
ORDER BY id DESC 
LIMIT 5;
"

# 3. Verify no escape sequences
sqlite3 data/full_intelligence.db "
SELECT description 
FROM pain_points 
WHERE description LIKE '%\\u00%'
LIMIT 1;
"
# Should return no results
```

---

## Troubleshooting

### Issue: Seeing \u00XX in database
**Solution**: Run the encoding fix script
```bash
python3 scripts/fix_spanish_encoding.py data/full_intelligence.db
```

### Issue: New interviews have encoding problems
**Solution**: Check compliance
```bash
python3 scripts/ensure_utf8_everywhere.py
```

### Issue: Exports have escaped characters
**Solution**: Ensure `ensure_ascii=False` is used
```python
json.dumps(data, ensure_ascii=False)
```

---

## Summary

‚úÖ **Database**: `text_factory = str` ensures UTF-8
‚úÖ **JSON**: `ensure_ascii=False` preserves Spanish characters
‚úÖ **Files**: `encoding='utf-8'` in all open() calls
‚úÖ **Helper**: `json_serialize()` function for consistent serialization
‚úÖ **Verified**: All code passes UTF-8 compliance check

**Result**: All future interviews will have proper Spanish character encoding! üá™üá∏

---

## Tools Created

1. **`scripts/ensure_utf8_everywhere.py`** - Check UTF-8 compliance
2. **`scripts/fix_spanish_encoding.py`** - Fix existing encoding issues
3. **`docs/UTF8_GUARANTEE.md`** - This document

**Status**: UTF-8 handling is now guaranteed for all future processing! ‚úÖ
